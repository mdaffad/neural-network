{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def readData(filename=\"xor-data.csv\"):\n",
    "    data = []\n",
    "    target_class = []\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append([int(row[\"x1\"]), int(row[\"x2\"])])\n",
    "            target_class.append(int(row[\"f\"]))\n",
    "    return data, target_class\n",
    "\n",
    "\n",
    "def readWeight(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    f1 = f.readlines()\n",
    "    activation = []\n",
    "    bias = []\n",
    "    weight = []\n",
    "    allowed = ['relu', 'sigmoid', 'linear', 'softmax']\n",
    "\n",
    "    n_attr = int(f1[0])\n",
    "    line = 1\n",
    "    while (line < len(f1)):\n",
    "        splitted = f1[line].strip('\\n').split(' ')\n",
    "        if (('relu' in splitted) or ('linear' in splitted) or ('sigmoid' in splitted) or ('softmax' in splitted)):\n",
    "            activation.append(splitted[1])\n",
    "\n",
    "            line += 1\n",
    "            splitted = f1[line].strip('\\n').split(' ')\n",
    "\n",
    "            bias.append(list(map(int, splitted)))\n",
    "        else:\n",
    "            temp = []\n",
    "            count = 0\n",
    "            while (count < n_attr):\n",
    "                splitted = f1[line].strip('\\n').split(' ')\n",
    "                temp.append(list(map(int, splitted)))\n",
    "                count += 1\n",
    "                line += 1\n",
    "            if (count == n_attr):\n",
    "                weight.append(temp)\n",
    "                line -= 1\n",
    "        line += 1\n",
    "    return activation, bias, weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def linear(x, kwargs=None):\n",
    "    return x\n",
    "\n",
    "def sigmoid(x, kwargs=None):\n",
    "    value = float(1 / (1 + math.exp(x * -1)))\n",
    "    threshold = kwargs.get(\"threshold\", None)\n",
    "    if threshold == None:\n",
    "        return value\n",
    "    else:\n",
    "        if value < threshold:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def relu(x, kwargs):\n",
    "    alpha = kwargs.get(\"alpha\", 0.0)\n",
    "    max_value = kwargs.get(\"max_value\", 1.0)\n",
    "    threshold = kwargs.get(\"threshold\", 0.0)\n",
    "    if x < threshold:\n",
    "        return max(x, x * alpha)\n",
    "    else:\n",
    "        if max_value == None:\n",
    "            return x\n",
    "        else:\n",
    "            return min(x, max_value)\n",
    "\n",
    "def softmax(arr):\n",
    "    arr_exp = np.exp(arr)\n",
    "    return arr_exp / arr_exp.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed Forward Neural Network : XOR\n",
      "=================================\n",
      "Activation \t: relu linear \n",
      "\n",
      "LAYER === 0\n",
      "Input layer \t: [0 0]\n",
      "\n",
      "LAYER === 1\n",
      "Input \t:  [0 0]\n",
      "Sigma \t:  [ 0 -1]\n",
      "Weight \t:  [[1 1]\n",
      " [1 1]]\n",
      "Result \t:  [0 0]\n",
      "\n",
      "LAYER === 2\n",
      "Input \t:  [0 0]\n",
      "Sigma \t:  [0]\n",
      "Weight \t:  [[ 1]\n",
      " [-2]]\n",
      "Result \t:  [0]\n",
      "\n",
      "LAYER === 0\n",
      "Input layer \t: [0 1]\n",
      "\n",
      "LAYER === 1\n",
      "Input \t:  [0 1]\n",
      "Sigma \t:  [1 0]\n",
      "Weight \t:  [[1 1]\n",
      " [1 1]]\n",
      "Result \t:  [1 0]\n",
      "\n",
      "LAYER === 2\n",
      "Input \t:  [1 0]\n",
      "Sigma \t:  [1]\n",
      "Weight \t:  [[ 1]\n",
      " [-2]]\n",
      "Result \t:  [1]\n",
      "\n",
      "LAYER === 0\n",
      "Input layer \t: [1 0]\n",
      "\n",
      "LAYER === 1\n",
      "Input \t:  [1 0]\n",
      "Sigma \t:  [1 0]\n",
      "Weight \t:  [[1 1]\n",
      " [1 1]]\n",
      "Result \t:  [1 0]\n",
      "\n",
      "LAYER === 2\n",
      "Input \t:  [1 0]\n",
      "Sigma \t:  [1]\n",
      "Weight \t:  [[ 1]\n",
      " [-2]]\n",
      "Result \t:  [1]\n",
      "\n",
      "LAYER === 0\n",
      "Input layer \t: [1 1]\n",
      "\n",
      "LAYER === 1\n",
      "Input \t:  [1 1]\n",
      "Sigma \t:  [2 1]\n",
      "Weight \t:  [[1 1]\n",
      " [1 1]]\n",
      "Result \t:  [2 1]\n",
      "\n",
      "LAYER === 2\n",
      "Input \t:  [2 1]\n",
      "Sigma \t:  [0]\n",
      "Weight \t:  [[ 1]\n",
      " [-2]]\n",
      "Result \t:  [0]\n",
      "Target Class \t:  [0, 1, 1, 0]\n",
      "Predict Class \t:  [array([0]), array([1]), array([1]), array([0])]\n",
      "=================================\n",
      "Result : Good Predict\n"
     ]
    }
   ],
   "source": [
    "from activation.activationFunction import linear, sigmoid, relu, softmax\n",
    "from dataReader import *\n",
    "\n",
    "# For iterating per item in array. Except for linear function because single parameter is automate to iterate per item\n",
    "linear = np.vectorize(linear)\n",
    "sigmoid = np.vectorize(sigmoid)\n",
    "relu = np.vectorize(relu)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.base_layer = []\n",
    "        self.current_layer = []\n",
    "\n",
    "    def get_total_layer(self):\n",
    "        return len(self.layer)\n",
    "\n",
    "    def enqueue_layer(self, layer):\n",
    "        self.base_layer.append(layer)\n",
    "\n",
    "    def deque_layer(self):\n",
    "        self.base_layer.pop(0)\n",
    "\n",
    "    def solve(self):\n",
    "        self.current_layer = self.base_layer.copy()\n",
    "        for idx in range(len(self.current_layer)):\n",
    "            print(\"\")\n",
    "            print(\"LAYER === \" + str(idx))\n",
    "            if idx != 0:\n",
    "                self.current_layer[idx].input_value = self.current_layer[idx-1].result\n",
    "            else:\n",
    "                print(\"Input layer \\t:\", self.current_layer[idx].input_value)\n",
    "                # print(self.current_layer[idx].input_value)\n",
    "            self.current_layer[idx].compute()\n",
    "\n",
    "\n",
    "class InputLayer:\n",
    "    def __init__(self, arr=[]):\n",
    "        self.input_value = np.array(arr)\n",
    "        self.result = self.input_value\n",
    "\n",
    "    def compute(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Layer(InputLayer):\n",
    "    def __init__(self, arr_weight, arr_bias, activation_function, **kwargs):\n",
    "        super().__init__([])\n",
    "        self.weight = np.array(arr_weight)\n",
    "        self.bias = np.array(arr_bias)\n",
    "        self.result = np.array([])\n",
    "        self.activation_function = activation_function\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def activate(self):\n",
    "        self.result = self.activation_function(self.result, self.kwargs)\n",
    "\n",
    "    def sigma(self):\n",
    "        # case 1 Dimension\n",
    "        if(len(self.weight[0]) == 1):\n",
    "            self.result = np.matmul(\n",
    "                self.input_value, self.weight.flatten()) + self.bias\n",
    "            # print(\"masuk 1\")\n",
    "\n",
    "        else:\n",
    "            self.result = np.matmul(self.input_value, self.weight) + self.bias\n",
    "        print(\"Sigma \\t: \", self.result)\n",
    "        # print(self.result)\n",
    "\n",
    "    def compute(self):\n",
    "        print(\"Input \\t: \", self.input_value)\n",
    "        # print(self.input_value)\n",
    "        self.sigma()\n",
    "        self.activate()\n",
    "\n",
    "        print(\"Weight \\t: \", self.weight)\n",
    "        # print(self.weight)\n",
    "        print(\"Result \\t: \", self.result)\n",
    "        # print(self.result)\n",
    "        # print(\"transpose\")\n",
    "        # print(np.transpose(\n",
    "        #     self.input_value))\n",
    "        # print(\"weight\")\n",
    "\n",
    "        # print(self.weight)\n",
    "        # print(\"result\")\n",
    "        # print(self.result)\n",
    "# driver test\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('Feed Forward Neural Network : XOR')\n",
    "    print(\"=================================\")\n",
    "\n",
    "    data_training, target = readData()\n",
    "    activation, bias, weight = readWeight('model 2.txt')\n",
    "    neural_network = NeuralNetwork()\n",
    "    result = []\n",
    "    layer = []\n",
    "\n",
    "    print(\"Activation \\t: \", end=\"\")\n",
    "    for i in range(len(activation)):\n",
    "        act = None\n",
    "        if (activation[i] == 'sigmoid'):\n",
    "            act = sigmoid\n",
    "        elif (activation[i] == 'linear'):\n",
    "            act = linear\n",
    "        elif (activation[i] == 'relu'):\n",
    "            act = relu\n",
    "        elif (activation[i] == 'softmax'):\n",
    "            act = softmax\n",
    "        print(activation[i], end=\" \")\n",
    "        layer.append(Layer(weight[i], bias[i], act, threshold=0.1))\n",
    "    print(\"\")\n",
    "    # layer.append(Layer([[20, -20], [20, -20]], [-10, 30], sigmoid, threshold=0.1))\n",
    "    # layer.append(Layer([[20, 20]], [-30], sigmoid,  threshold=0.1))\n",
    "    for data in data_training:\n",
    "        layer.insert(0, InputLayer(data))\n",
    "        neural_network.base_layer = layer\n",
    "        neural_network.solve()\n",
    "        result.append(neural_network.current_layer[-1].result)\n",
    "        neural_network.deque_layer()\n",
    "    print(\"Target Class \\t: \", target)\n",
    "    print(\"Predict Class \\t: \", result)\n",
    "    print(\"=================================\")\n",
    "    if (result == target):\n",
    "        print(\"Result : Good Predict\")\n",
    "    else:\n",
    "        print(\"Result : Wrong Predict\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # print(data)\n",
    "    # print(target)\n",
    "    # readWeight()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
